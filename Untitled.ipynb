{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build an NLP model to analyze Twitter sentiment about Apple and Google products. The dataset comes from CrowdFlower via data.world Links. Human raters rated the sentiment in over 9,000 Tweets as positive, negative, or neither.\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "Build a model that can rate the sentiment of a Tweet based on its content.\n",
    "\n",
    "Aim for a Proof of Concept\n",
    "There are many approaches to NLP problems - start with something simple and iterate from there. For example, you could start by limiting your analysis to positive and negative Tweets only, allowing you to build a binary classifier. Then you could add in the neutral Tweets to build out a multiclass classifier. You may also consider using some of the more advanced NLP methods in the Mod 4 Appendix.\n",
    "\n",
    "Evaluation\n",
    "Evaluating multiclass classifiers can be trickier than binary classifiers because there are multiple ways to mis-classify an observation, and some errors are more problematic than others. Use the business problem that your NLP project sets out to solve to inform your choice of evaluation metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/tweet_product_company.csv', encoding = 'unicode_escape')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5389\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             label\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  Negative emotion\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  Positive emotion\n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...  Positive emotion\n",
       "3  @sxsw I hope this year's festival isn't as cra...  Negative emotion\n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  Positive emotion"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[['tweet_text', 'is_there_an_emotion_directed_at_a_brand_or_product']]\n",
    "data = data.rename(columns = {'tweet_text' : 'text', 'is_there_an_emotion_directed_at_a_brand_or_product' : 'label'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5389\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I cant tell                            156\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'] = data['label'].replace(\"[',]\", \"\", regex=True)\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral emotion     5545\n",
       "Positive emotion    2978\n",
       "Negative emotion     570\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].replace('No emotion toward brand or product', 'Neutral emotion', inplace=True)\n",
    "data['label'].replace('I cant tell', 'Neutral emotion', inplace=True)\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Counts:\n",
      "Neutral emotion     5545\n",
      "Positive emotion    2978\n",
      "Negative emotion     570\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Percentages:\n",
      "Neutral emotion     0.609810\n",
      "Positive emotion    0.327505\n",
      "Negative emotion    0.062686\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for class imbalance\n",
    "print(\"Raw Counts:\")\n",
    "print(data['label'].value_counts())\n",
    "print()\n",
    "print('Percentages:')\n",
    "print(data['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of values in column 'stroke'\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.countplot(data['label'])\n",
    "plt.title('Distribution of Twitter Sentiment')\n",
    "plt.savefig('distribution_sentiment');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    9092 non-null   object\n",
      " 1   label   9093 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 142.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9092 entries, 0 to 9092\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    9092 non-null   object\n",
      " 1   label   9092 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 213.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...      2\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...      1\n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...      1\n",
       "3  @sxsw I hope this year's festival isn't as cra...      2\n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = {\n",
    "    'Neutral emotion' : 0,\n",
    "    'Positive emotion' : 1,\n",
    "    'Negative emotion' : 2\n",
    "}\n",
    "label_data = data['label'].map(label)\n",
    "\n",
    "new_df = data.copy()\n",
    "new_df['label'] = label_data\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9092 entries, 0 to 9092\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    9092 non-null   object\n",
      " 1   label   9092 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 213.1+ KB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df['text']\n",
    "y = new_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4185\n",
      "1    2215\n",
      "2     419\n",
      "Name: label, dtype: int64 \n",
      "\n",
      " 0    1359\n",
      "1     763\n",
      "2     151\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.25)\n",
    "print(y_train.value_counts(),'\\n\\n', y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8605</th>\n",
       "      <td>Perfect attention to detail RT @mention Google...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>my iphone was stolen and I got it back !!!!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>fuck I love Austin. Just left the Youtube Goog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>Spotted something rare a few minutes ago...a p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>@mention fyi  RT @mention I'll be at the Austi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "8605  Perfect attention to detail RT @mention Google...\n",
       "1303  my iphone was stolen and I got it back !!!!!! ...\n",
       "8759  fuck I love Austin. Just left the Youtube Goog...\n",
       "5021  Spotted something rare a few minutes ago...a p...\n",
       "3210  @mention fyi  RT @mention I'll be at the Austi..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train, columns = ['text'])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8605</th>\n",
       "      <td>perfect attention to detail rt @mention google...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>my iphone was stolen and i got it back !!!!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>fuck i love austin. just left the youtube goog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>spotted something rare a few minutes ago...a p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>@mention fyi  rt @mention i'll be at the austi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "8605  perfect attention to detail rt @mention google...\n",
       "1303  my iphone was stolen and i got it back !!!!!! ...\n",
       "8759  fuck i love austin. just left the youtube goog...\n",
       "5021  spotted something rare a few minutes ago...a p...\n",
       "3210  @mention fyi  rt @mention i'll be at the austi..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing \n",
    "# Transform sample data to lowercase\n",
    "X_train['text'] = X_train['text'].str.lower()\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6819 entries, 8605 to 7271\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    6819 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 106.5+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0b60f7065d1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(\"@[A-Za-z0-9_]+\")'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregexp_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/nltk/tokenize/regexp.py\u001b[0m in \u001b[0;36mregexp_tokenize\u001b[0;34m(text, pattern, gaps, discard_empty, flags)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \"\"\"\n\u001b[1;32m    215\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegexpTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscard_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/nltk/tokenize/regexp.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# If our regexp matches tokens, use re.findall:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_regexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "pattern = '(\"@[A-Za-z0-9_]+\")'\n",
    "X_train['clean'] = nltk.regexp_tokenize(X_train, pattern)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8605</th>\n",
       "      <td>perfect attention to detail rt @mention google...</td>\n",
       "      <td>[perfect, attention, to, detail, rt, mention, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>my iphone was stolen and i got it back !!!!!! ...</td>\n",
       "      <td>[my, iphone, was, stolen, and, got, it, back, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>fuck i love austin. just left the youtube goog...</td>\n",
       "      <td>[fuck, love, austin, just, left, the, youtube,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>spotted something rare a few minutes ago...a p...</td>\n",
       "      <td>[spotted, something, rare, few, minutes, ago, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>@mention fyi  rt @mention i'll be at the austi...</td>\n",
       "      <td>[mention, fyi, rt, mention, ll, be, at, the, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "8605  perfect attention to detail rt @mention google...   \n",
       "1303  my iphone was stolen and i got it back !!!!!! ...   \n",
       "8759  fuck i love austin. just left the youtube goog...   \n",
       "5021  spotted something rare a few minutes ago...a p...   \n",
       "3210  @mention fyi  rt @mention i'll be at the austi...   \n",
       "\n",
       "                                              tokenized  \n",
       "8605  [perfect, attention, to, detail, rt, mention, ...  \n",
       "1303  [my, iphone, was, stolen, and, got, it, back, ...  \n",
       "8759  [fuck, love, austin, just, left, the, youtube,...  \n",
       "5021  [spotted, something, rare, few, minutes, ago, ...  \n",
       "3210  [mention, fyi, rt, mention, ll, be, at, the, a...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "basic_token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "tokenizer = RegexpTokenizer(basic_token_pattern)\n",
    "X_train['tokenized'] = X_train['text'].apply(tokenizer.tokenize)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8605</th>\n",
       "      <td>perfect attention to detail rt @mention google...</td>\n",
       "      <td>[perfect, attention, to, detail, rt, mention, ...</td>\n",
       "      <td>[perfect, attention, detail, rt, mention, goog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>my iphone was stolen and i got it back !!!!!! ...</td>\n",
       "      <td>[my, iphone, was, stolen, and, got, it, back, ...</td>\n",
       "      <td>[iphone, stolen, got, back, sxsw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>fuck i love austin. just left the youtube goog...</td>\n",
       "      <td>[fuck, love, austin, just, left, the, youtube,...</td>\n",
       "      <td>[fuck, love, austin, left, youtube, google, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>spotted something rare a few minutes ago...a p...</td>\n",
       "      <td>[spotted, something, rare, few, minutes, ago, ...</td>\n",
       "      <td>[spotted, something, rare, minutes, ago, phone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>@mention fyi  rt @mention i'll be at the austi...</td>\n",
       "      <td>[mention, fyi, rt, mention, ll, be, at, the, a...</td>\n",
       "      <td>[mention, fyi, rt, mention, austin, convention...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "8605  perfect attention to detail rt @mention google...   \n",
       "1303  my iphone was stolen and i got it back !!!!!! ...   \n",
       "8759  fuck i love austin. just left the youtube goog...   \n",
       "5021  spotted something rare a few minutes ago...a p...   \n",
       "3210  @mention fyi  rt @mention i'll be at the austi...   \n",
       "\n",
       "                                              tokenized  \\\n",
       "8605  [perfect, attention, to, detail, rt, mention, ...   \n",
       "1303  [my, iphone, was, stolen, and, got, it, back, ...   \n",
       "8759  [fuck, love, austin, just, left, the, youtube,...   \n",
       "5021  [spotted, something, rare, few, minutes, ago, ...   \n",
       "3210  [mention, fyi, rt, mention, ll, be, at, the, a...   \n",
       "\n",
       "                                           no_stopwords  \n",
       "8605  [perfect, attention, detail, rt, mention, goog...  \n",
       "1303                  [iphone, stolen, got, back, sxsw]  \n",
       "8759  [fuck, love, austin, left, youtube, google, pa...  \n",
       "5021  [spotted, something, rare, minutes, ago, phone...  \n",
       "3210  [mention, fyi, rt, mention, austin, convention...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(token_list):\n",
    "    stopwords_removed = [token for token in token_list if token not in stopwords_list]\n",
    "    return stopwords_removed\n",
    "\n",
    "X_train['no_stopwords'] = X_train['tokenized'].apply(remove_stopwords)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'perfect attention to detail rt @mention google recreated the code for pac-man for their doodle, original bugs included. #sxsw #googledoodles'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iphone', 'stolen', 'got', 'back', 'sxsw']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['no_stopwords'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
